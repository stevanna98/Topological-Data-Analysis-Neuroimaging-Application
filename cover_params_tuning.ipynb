{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cover Parameters Tuning\n",
    "This notebook runs a parameter sweep over TDA graph cover parameters (`perc_overlap` and `n_cubes`) across different feature sets and filter functions, evaluating each configuration using Louvain community detection modularity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tda.tda_graph import TDAGraph\n",
    "from tuning.heatmap_creation import Heatmap\n",
    "from tuning.tuning_utils import *\n",
    "from community_detection.community import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed_value = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "Edit the paths and parameters below before running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── File paths ──────────────────────────────────────────────────────────────\n",
    "FMRI_PATH      = \"path/to/fmri.csv\"\n",
    "ENV_PATH       = \"path/to/env.csv\"\n",
    "DEMO_PATH      = \"path/to/demo_vars.csv\"\n",
    "OUTPUT_DIR     = \"path/to/output\"\n",
    "\n",
    "# ── Clustering / distance ────────────────────────────────────────────────────\n",
    "METRIC         = \"chebyshev\"\n",
    "CLUSTERER      = \"dbscan\"\n",
    "MIN_SAMPLES    = 3\n",
    "EPS            = 8.0\n",
    "\n",
    "# ── Bootstrap ────────────────────────────────────────────────────────────────\n",
    "N_BOOTSTRAP    = 10\n",
    "BOOTSTRAP_RATIO = 0.7\n",
    "\n",
    "# ── Parameter grid ───────────────────────────────────────────────────────────\n",
    "perc_overlap = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "n_cubes      = [10, 20, 30, 40, 50, 60]\n",
    "\n",
    "# ── Experiment dimensions ────────────────────────────────────────────────────\n",
    "feature_sets = ['all', 'fmri', 'env']\n",
    "filter_funcs = ['umap', 'pca', 'tsne', 'isomap']\n",
    "\n",
    "# Toggle demographic variables\n",
    "demographic  = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_df  = pd.read_csv(FMRI_PATH)\n",
    "env_df   = pd.read_csv(ENV_PATH)\n",
    "demo_df  = pd.read_csv(DEMO_PATH)\n",
    "\n",
    "new_demo_df = demo_df[['SEX', 'AGE', 'EDU']]\n",
    "\n",
    "print(f\"fMRI shape   : {fmri_df.shape}\")\n",
    "print(f\"Env shape    : {env_df.shape}\")\n",
    "print(f\"Demo shape   : {new_demo_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Helper — Build Feature Matrix\n",
    "Assembles the right columns depending on `feature` and `demographic` settings, then applies `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_matrix(feature: str, demographic: bool) -> pd.DataFrame:\n",
    "    \"\"\"Concatenate the requested data blocks and return a scaled DataFrame.\"\"\"\n",
    "    if demographic:\n",
    "        blocks = {\n",
    "            'all':  [fmri_df, env_df, new_demo_df],\n",
    "            'fmri': [fmri_df, new_demo_df],\n",
    "            'env':  [env_df,  new_demo_df],\n",
    "        }\n",
    "    else:\n",
    "        blocks = {\n",
    "            'all':  [fmri_df, env_df],\n",
    "            'fmri': [fmri_df],\n",
    "            'env':  [env_df],\n",
    "        }\n",
    "\n",
    "    data = pd.concat(blocks[feature], axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    return pd.DataFrame(data_scaled, columns=data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parameter Tuning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_overlap_labels = [str(v) for v in perc_overlap]\n",
    "n_cubes_labels      = [str(v) for v in n_cubes]\n",
    "\n",
    "for filter_ in filter_funcs:\n",
    "    for feature in feature_sets:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Filter: {filter_}  |  Feature set: {feature}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # ── Prepare data ────────────────────────────────────────────\n",
    "        data_scaled = build_feature_matrix(feature, demographic)\n",
    "\n",
    "        # ── Bootstrap samples ────────────────────────────────────────\n",
    "        bootstrap_samples = get_bootstrap_samples(\n",
    "            df=data_scaled,\n",
    "            n_bootstrap=N_BOOTSTRAP,\n",
    "            ratio=BOOTSTRAP_RATIO,\n",
    "            seed_value=seed_value\n",
    "        )\n",
    "\n",
    "        # ── Result matrices ──────────────────────────────────────────\n",
    "        results_snr = np.zeros((len(perc_overlap), len(n_cubes)))\n",
    "        results_avg = np.zeros((len(perc_overlap), len(n_cubes)))\n",
    "        results_std = np.zeros((len(perc_overlap), len(n_cubes)))\n",
    "\n",
    "        # ── Grid search ──────────────────────────────────────────────\n",
    "        for i, resolution in enumerate(perc_overlap):\n",
    "            for j, gain in enumerate(n_cubes):\n",
    "                print(f\"  overlap={resolution}, n_cubes={gain}\", end=\"  →  \")\n",
    "\n",
    "                modularity_list = []\n",
    "                for k in range(len(bootstrap_samples)):\n",
    "                    tdagraph = TDAGraph(\n",
    "                        X=bootstrap_samples[k],\n",
    "                        filter_func=filter_,\n",
    "                        n_cubes=gain,\n",
    "                        perc_overlap=resolution,\n",
    "                        cluster_algorithm=CLUSTERER,\n",
    "                        min_samples=MIN_SAMPLES,\n",
    "                        metric=METRIC,\n",
    "                        eps=EPS,\n",
    "                    )\n",
    "                    graph = tdagraph.create_graph()\n",
    "\n",
    "                    community = Community(\n",
    "                        graph[0],\n",
    "                        algorithm='louvain',\n",
    "                        seed_value=seed_value,\n",
    "                        dataset=pd.DataFrame(bootstrap_samples[k])\n",
    "                    )\n",
    "                    community.community_detection(k=10)\n",
    "                    modularity_list.append(community.compute_modularity())\n",
    "\n",
    "                avg_mod = np.mean(modularity_list)\n",
    "                std_mod = np.std(modularity_list)\n",
    "                snr_mod = 0 if avg_mod <= 0.3 else avg_mod / std_mod\n",
    "\n",
    "                results_snr[i, j] = snr_mod\n",
    "                results_avg[i, j] = avg_mod\n",
    "                results_std[i, j] = std_mod\n",
    "\n",
    "                print(f\"avg={avg_mod:.4f}  std={std_mod:.4f}  SNR={snr_mod:.4f}\")\n",
    "\n",
    "        # ── Save heatmaps ────────────────────────────────────────────\n",
    "        tag = f\"{filter_}_{METRIC}_{feature}\"\n",
    "\n",
    "        for matrix, label in [\n",
    "            (results_snr, \"snr_composite_score\"),\n",
    "            (results_avg, \"avg_modularity_score\"),\n",
    "            (results_std, \"std_modularity_score\"),\n",
    "        ]:\n",
    "            heatmap = Heatmap(\n",
    "                matrix=matrix,\n",
    "                cmap='viridis',\n",
    "                perc_overlap_values=perc_overlap_labels,\n",
    "                n_cubes_values=n_cubes_labels,\n",
    "            )\n",
    "            heatmap.save(output_path=f\"{OUTPUT_DIR}/{label}_heatmap_{tag}.png\")\n",
    "            print(f\"  Saved: {label}_heatmap_{tag}.png\")\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
